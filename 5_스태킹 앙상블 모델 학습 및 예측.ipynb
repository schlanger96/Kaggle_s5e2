{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:gray; padding:15px; border-radius:10px; font-size:20px; color:white;\">\n",
    "    <h2 style=\"margin-bottom:10px;\">스태킹 앙상블 목차</h2>\n",
    "    <ol style=\"padding-left:20px;\">\n",
    "        <li>(시도 1) 메타모델을 XGB 모델로 학습</li>\n",
    "        <li>(시도 2) 메타모델을 릿지 회귀모형으로 학습</li>\n",
    "        <li>(시도 3) 메타모델을 릿지 회귀모형으로 학습 (다른 알파값)</li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from sklearn.metrics import root_mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_train_df = pd.read_csv('te_train_df')\n",
    "te_test_df = pd.read_csv('te_test_df')\n",
    "y_df = pd.read_csv('y_df')\n",
    "sub = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_TE</th>\n",
       "      <th>Material_TE</th>\n",
       "      <th>Size_TE</th>\n",
       "      <th>Compartments_TE</th>\n",
       "      <th>Laptop Compartment_TE</th>\n",
       "      <th>Waterproof_TE</th>\n",
       "      <th>Style_TE</th>\n",
       "      <th>Color_TE</th>\n",
       "      <th>Weight Capacity (kg)_TE</th>\n",
       "      <th>Missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.766600</td>\n",
       "      <td>80.482808</td>\n",
       "      <td>81.197151</td>\n",
       "      <td>81.608400</td>\n",
       "      <td>81.418773</td>\n",
       "      <td>81.431367</td>\n",
       "      <td>81.498538</td>\n",
       "      <td>80.319375</td>\n",
       "      <td>82.699785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81.777256</td>\n",
       "      <td>81.831401</td>\n",
       "      <td>81.471377</td>\n",
       "      <td>81.548357</td>\n",
       "      <td>81.425348</td>\n",
       "      <td>81.413824</td>\n",
       "      <td>81.189047</td>\n",
       "      <td>82.238982</td>\n",
       "      <td>81.365737</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.068264</td>\n",
       "      <td>80.489584</td>\n",
       "      <td>81.460863</td>\n",
       "      <td>81.615232</td>\n",
       "      <td>81.417223</td>\n",
       "      <td>81.437409</td>\n",
       "      <td>81.188867</td>\n",
       "      <td>81.008732</td>\n",
       "      <td>81.360793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81.286106</td>\n",
       "      <td>81.059274</td>\n",
       "      <td>81.461402</td>\n",
       "      <td>81.724961</td>\n",
       "      <td>81.418773</td>\n",
       "      <td>81.431367</td>\n",
       "      <td>81.188657</td>\n",
       "      <td>82.235106</td>\n",
       "      <td>81.356545</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.528193</td>\n",
       "      <td>81.827587</td>\n",
       "      <td>81.203076</td>\n",
       "      <td>81.037864</td>\n",
       "      <td>81.433576</td>\n",
       "      <td>81.422242</td>\n",
       "      <td>81.194270</td>\n",
       "      <td>82.264042</td>\n",
       "      <td>81.369522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand_TE  Material_TE    Size_TE  Compartments_TE  Laptop Compartment_TE  \\\n",
       "0  81.766600    80.482808  81.197151        81.608400              81.418773   \n",
       "1  81.777256    81.831401  81.471377        81.548357              81.425348   \n",
       "2  82.068264    80.489584  81.460863        81.615232              81.417223   \n",
       "3  81.286106    81.059274  81.461402        81.724961              81.418773   \n",
       "4  80.528193    81.827587  81.203076        81.037864              81.433576   \n",
       "\n",
       "   Waterproof_TE   Style_TE   Color_TE  Weight Capacity (kg)_TE  Missing_count  \n",
       "0      81.431367  81.498538  80.319375                82.699785              0  \n",
       "1      81.413824  81.189047  82.238982                81.365737              0  \n",
       "2      81.437409  81.188867  81.008732                81.360793              0  \n",
       "3      81.431367  81.188657  82.235106                81.356545              0  \n",
       "4      81.422242  81.194270  82.264042                81.369522              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------- Xgb 모델 OOF 값 생성 --------------------------------------------------\n",
    "\n",
    "# XGBoost 최적 하이퍼파라미터\n",
    "xgb_params = {\n",
    "    'learning_rate': 0.013703799543482834,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.9146994136721976,\n",
    "    'min_child_weight': 4,\n",
    "    'colsample_bytree': 0.873195834229002,\n",
    "    'gamma': 1.4319945252821071,\n",
    "    'reg_alpha': 5.208058683903292,\n",
    "    'reg_lambda': 9.29985066405108,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"objective\": \"reg:squarederror\"\n",
    "}\n",
    "\n",
    "num_boost_round = 573  \n",
    "\n",
    "# K-Fold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state= 1)\n",
    "\n",
    "# OOF Predictions 저장 공간 (훈련 데이터 크기만큼)\n",
    "xgb_oof_series = pd.Series(np.zeros(te_train_df.shape[0]), index=te_train_df.index)\n",
    "\n",
    "# 테스트 데이터 예측값 저장 (K-Fold 평균)\n",
    "xgb_test_preds = np.zeros(te_test_df.shape[0])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(te_train_df)):\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_tr, X_val = te_train_df.iloc[train_idx], te_train_df.iloc[val_idx]\n",
    "    y_tr, y_val = y_df.iloc[train_idx], y_df.iloc[val_idx]\n",
    "\n",
    "    # DMatrix 변환 (XGBoost 전용 데이터 포맷)\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    dtest = xgb.DMatrix(te_test_df)\n",
    "\n",
    "    # XGBoost 모델 학습 (num_boost_round 사용)\n",
    "    final_xgb_model = xgb.train(params=xgb_params, dtrain=dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "    # 검증 데이터 OOF 예측값 저장\n",
    "    xgb_oof_series.iloc[val_idx] = final_xgb_model.predict(dval)\n",
    "\n",
    "    # 테스트 데이터 예측값 저장 (K-Fold 평균 계산을 위해 누적)\n",
    "    xgb_test_preds += final_xgb_model.predict(dtest) / kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------- LGBM 모델 OOF 값 생성 --------------------------------------------------\n",
    "\n",
    "# LightGBM 최적 하이퍼파라미터 (Optuna 결과 적용)\n",
    "lgbm_params = {\n",
    "    'n_estimators': 1610,\n",
    "    'learning_rate': 0.010778996386807065,\n",
    "    'max_depth': 16,\n",
    "    'num_leaves': 60,\n",
    "    'min_child_samples': 10,\n",
    "    'subsample': 0.9878765234269894,\n",
    "    'colsample_bytree': 0.6686529815076371,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'device': 'gpu', \n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# K-Fold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state= 1)\n",
    "\n",
    "# OOF Predictions 저장 공간 (훈련 데이터 크기만큼)\n",
    "lgbm_oof_series = pd.Series(np.zeros(te_train_df.shape[0]), index=te_train_df.index)\n",
    "\n",
    "# 테스트 데이터 예측값 저장 (K-Fold 평균)\n",
    "lgbm_test_preds = np.zeros(te_test_df.shape[0])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(te_train_df)):\n",
    "    # 데이터 분할\n",
    "    X_tr, X_val = te_train_df.iloc[train_idx], te_train_df.iloc[val_idx]\n",
    "    y_tr, y_val = y_df.iloc[train_idx], y_df.iloc[val_idx]\n",
    "\n",
    "    # LightGBM 모델 학습\n",
    "    lgbm_model = LGBMRegressor(**lgbm_params, early_stopping_rounds=100)\n",
    "    lgbm_model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)])\n",
    "    \n",
    "    # 검증 데이터 OOF 예측값 저장\n",
    "    lgbm_oof_series.iloc[val_idx] = lgbm_model.predict(X_val)\n",
    "\n",
    "    # 테스트 데이터 예측값 저장 (K-Fold 평균 계산을 위해 누적)\n",
    "    lgbm_test_preds += lgbm_model.predict(te_test_df) / kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------- Cat_boost 모델 OOF 값 생성 --------------------------------------------------\n",
    "\n",
    "# CatBoost 최적 하이퍼파라미터 (Optuna 결과 적용)\n",
    "cat_params = {\n",
    "    'iterations': 1498,\n",
    "    'learning_rate': 0.03254917389751133,\n",
    "    'depth': 6,\n",
    "    'l2_leaf_reg': 8.900690628691112,\n",
    "    'task_type': 'GPU', \n",
    "    'devices': '0',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# K-Fold 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state= 1)\n",
    "\n",
    "# OOF Predictions 저장 공간 (훈련 데이터 크기만큼)\n",
    "cat_oof_series = pd.Series(np.zeros(te_train_df.shape[0]), index=te_train_df.index)\n",
    "\n",
    "# 테스트 데이터 예측값 저장 (K-Fold 평균)\n",
    "cat_test_preds = np.zeros(te_test_df.shape[0])\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(te_train_df)):\n",
    "    # 데이터 분할\n",
    "    X_tr, X_val = te_train_df.iloc[train_idx], te_train_df.iloc[val_idx]\n",
    "    y_tr, y_val = y_df.iloc[train_idx], y_df.iloc[val_idx]\n",
    "\n",
    "    # CatBoost 모델 학습\n",
    "    cat_model = CatBoostRegressor(**cat_params)\n",
    "    cat_model.fit(X_tr, y_tr, eval_set=(X_val, y_val), early_stopping_rounds=100, use_best_model=True)\n",
    "\n",
    "    # 검증 데이터 OOF 예측값 저장\n",
    "    cat_oof_series.iloc[val_idx] = cat_model.predict(X_val)\n",
    "\n",
    "    # 테스트 데이터 예측값 저장 (K-Fold 평균 계산을 위해 누적)\n",
    "    cat_test_preds += cat_model.predict(te_test_df) / kf.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1️⃣ 메타 모델 학습을 위한 훈련 데이터 (OOF 예측값 기반)\n",
    "train_meta_df = pd.DataFrame({\n",
    "    \"xgb_oof\": xgb_oof_series,\n",
    "    \"lgbm_oof\": lgbm_oof_series,\n",
    "    \"cat_oof\": cat_oof_series\n",
    "})\n",
    "\n",
    "# 2️⃣ 메타 모델이 테스트 데이터 예측할 때 사용할 데이터 (Base Model들의 K-Fold 평균 예측값 기반)\n",
    "test_meta_df = pd.DataFrame({\n",
    "    \"xgb_oof\": xgb_test_preds,\n",
    "    \"lgbm_oof\": lgbm_test_preds,\n",
    "    \"cat_oof\": cat_test_preds\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(앙상블 시도 1)<br>\n",
    "xgb를 메타모델로\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-25 11:10:02,230] A new study created in memory with name: no-name-273c0a7c-3922-4abb-8b5c-17e944f6fea6\n",
      "[I 2025-02-25 11:15:17,688] Trial 0 finished with value: 38.70202457761227 and parameters: {'n_estimators': 1166, 'learning_rate': 0.007701874349537306, 'max_depth': 30, 'num_leaves': 126}. Best is trial 0 with value: 38.70202457761227.\n",
      "[I 2025-02-25 11:16:51,123] Trial 1 finished with value: 38.70154998568181 and parameters: {'n_estimators': 1856, 'learning_rate': 0.031121490581125528, 'max_depth': 14, 'num_leaves': 93}. Best is trial 1 with value: 38.70154998568181.\n",
      "[I 2025-02-25 11:18:59,654] Trial 2 finished with value: 38.70234919140915 and parameters: {'n_estimators': 1262, 'learning_rate': 0.02298214814059472, 'max_depth': 11, 'num_leaves': 134}. Best is trial 1 with value: 38.70154998568181.\n",
      "[I 2025-02-25 11:22:02,193] Trial 3 finished with value: 38.701848326495615 and parameters: {'n_estimators': 972, 'learning_rate': 0.013078110916209282, 'max_depth': 19, 'num_leaves': 113}. Best is trial 1 with value: 38.70154998568181.\n",
      "[I 2025-02-25 11:22:40,650] Trial 4 finished with value: 38.700786219079845 and parameters: {'n_estimators': 106, 'learning_rate': 0.04789074171148944, 'max_depth': 6, 'num_leaves': 138}. Best is trial 4 with value: 38.700786219079845.\n",
      "[I 2025-02-25 11:23:35,867] Trial 5 finished with value: 38.7002833890795 and parameters: {'n_estimators': 594, 'learning_rate': 0.03798806376452982, 'max_depth': 12, 'num_leaves': 22}. Best is trial 5 with value: 38.7002833890795.\n",
      "[I 2025-02-25 11:24:56,724] Trial 6 finished with value: 38.70034134540381 and parameters: {'n_estimators': 707, 'learning_rate': 0.024262408554190217, 'max_depth': 6, 'num_leaves': 25}. Best is trial 5 with value: 38.7002833890795.\n",
      "[I 2025-02-25 11:28:39,016] Trial 7 finished with value: 38.70139474539704 and parameters: {'n_estimators': 2438, 'learning_rate': 0.00983567501293915, 'max_depth': 20, 'num_leaves': 87}. Best is trial 5 with value: 38.7002833890795.\n",
      "[I 2025-02-25 11:31:30,869] Trial 8 finished with value: 38.70023141868663 and parameters: {'n_estimators': 2107, 'learning_rate': 0.011183706054495349, 'max_depth': 5, 'num_leaves': 125}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:33:40,432] Trial 9 finished with value: 38.70075276670799 and parameters: {'n_estimators': 355, 'learning_rate': 0.015050870682635265, 'max_depth': 22, 'num_leaves': 48}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:35:40,937] Trial 10 finished with value: 38.70101079825007 and parameters: {'n_estimators': 1890, 'learning_rate': 0.01860006556288807, 'max_depth': 34, 'num_leaves': 63}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:36:38,243] Trial 11 finished with value: 38.70049591622594 and parameters: {'n_estimators': 1778, 'learning_rate': 0.03729170943344094, 'max_depth': 12, 'num_leaves': 31}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:38:01,423] Trial 12 finished with value: 38.701897167861866 and parameters: {'n_estimators': 2491, 'learning_rate': 0.03991754506254145, 'max_depth': 8, 'num_leaves': 106}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:39:18,048] Trial 13 finished with value: 38.701010316964606 and parameters: {'n_estimators': 583, 'learning_rate': 0.03160271905511527, 'max_depth': 15, 'num_leaves': 63}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:40:45,244] Trial 14 finished with value: 38.70268773738076 and parameters: {'n_estimators': 1551, 'learning_rate': 0.045390940572811345, 'max_depth': 9, 'num_leaves': 148}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:41:46,989] Trial 15 finished with value: 38.700232263360746 and parameters: {'n_estimators': 2172, 'learning_rate': 0.03934569621007374, 'max_depth': 5, 'num_leaves': 70}. Best is trial 8 with value: 38.70023141868663.\n",
      "[I 2025-02-25 11:42:57,297] Trial 16 finished with value: 38.700248406814225 and parameters: {'n_estimators': 2170, 'learning_rate': 0.0313697901957636, 'max_depth': 5, 'num_leaves': 70}. Best is trial 8 with value: 38.70023141868663.\n",
      "[W 2025-02-25 11:45:50,655] Trial 17 failed with parameters: {'n_estimators': 2138, 'learning_rate': 0.005437237403507426, 'max_depth': 25, 'num_leaves': 107} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<timed exec>\", line 31, in objective\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-25 11:45:50,660] Trial 17 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:43\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m<timed exec>:31\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[0m, in \u001b[0;36mLGBMRegressor.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   1382\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1383\u001b[0m     X: _LGBM_ScikitMatrixLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1395\u001b[0m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1396\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLGBMRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1398\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\engine.py:322\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    311\u001b[0m     cb(\n\u001b[0;32m    312\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    313\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m         )\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 322\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightgbm\\basic.py:4155\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4154\u001b[0m _safe_call(\n\u001b[1;32m-> 4155\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4159\u001b[0m )\n\u001b[0;32m   4160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# 학습과정 로그 출력 활성화\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'n_estimators' : trial.suggest_int(\"n_estimators\", 100, 2500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 35),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'random_state': 1,\n",
    "        'device': 'gpu', \n",
    "        'gpu_platform_id': 0,\n",
    "        'gpu_device_id': 0,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "    kf = KFold(n_splits = 5, shuffle= True, random_state= 1)\n",
    "\n",
    "    rmse_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(train_meta_df):\n",
    "        x_train, x_val = train_meta_df.iloc[train_index], train_meta_df.iloc[val_index]\n",
    "        y_train, y_val = y_df.iloc[train_index], y_df.iloc[val_index]\n",
    "\n",
    "        lgbm_model = LGBMRegressor(**params, early_stopping_rounds=100)\n",
    "        lgbm_model.fit(x_train, y_train, eval_set=[(x_val, y_val)])\n",
    "        \n",
    "        y_pred = lgbm_model.predict(x_val)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        rmse_scores.append(rmse)\n",
    "\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "n_trials = 200\n",
    "lgbm_study = optuna.create_study(direction = 'minimize')\n",
    "lgbm_study.optimize(objective, n_trials=n_trials, catch=Exception)\n",
    "       \n",
    "# 최적 결과 출력\n",
    "print(\"\\n최고의 RMSE값:\", lgbm_study.best_value)\n",
    "print(\"최고의 하이퍼파라미터:\", lgbm_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "    Feature  Importance\n",
      "2   cat_oof       19665\n",
      "1  lgbm_oof       18868\n",
      "0   xgb_oof       17238\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------------------------------- 최적 파라미터로 학습 후 제출 ----------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "best_params = lgbm_study.best_params\n",
    "best_params.update({\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'device': 'gpu', \n",
    "    'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'verbose': -1\n",
    "    })\n",
    "\n",
    "\n",
    "# 최적의 파라미터로 최종 모델 학습\n",
    "lgbm_model = LGBMRegressor(**best_params)\n",
    "final_lgbm_model = lgbm_model.fit(train_meta_df, y_df)\n",
    "\n",
    "# 예측\n",
    "y_pred = final_lgbm_model.predict(test_meta_df)\n",
    "\n",
    "# ------------------------------------------------------ 변수 중요도 추출 및 시각화 ------------------------------------------------------\n",
    "\n",
    "# 중요도 numpy 배열 생성\n",
    "feature_importances = final_lgbm_model.feature_importances_\n",
    "\n",
    "# 데이터프레임 변환\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': train_meta_df.columns, \n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 변수 중요도 출력\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n",
    "\n",
    "# 변수 중요도 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance (LightGBM)')\n",
    "plt.gca().invert_yaxis()  # 중요도가 높은 순서로 표시\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "# 제출 파일 생성\n",
    "stacking_sub2 = sub.copy()\n",
    "stacking_sub2['Price'] = y_pred\n",
    "stacking_sub2.to_csv('stacking_sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(앙상블 시도 2)<br>\n",
    "릿지를 메타모델로\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Ridge 메타 모델 학습\n",
    "meta_model = Ridge(alpha=1.0)  \n",
    "meta_model.fit(train_meta_df, y_df)\n",
    "\n",
    "# 최종 예측 수행\n",
    "final_preds = meta_model.predict(test_meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "# 제출 파일 생성\n",
    "ridge_sub1 = sub.copy()\n",
    "ridge_sub1['Price'] = final_preds\n",
    "ridge_sub1.to_csv('ridge_sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:red; padding:10px; border-radius:10px; font-size:18px;\">\n",
    "(앙상블 시도 3))<br>\n",
    "릿지 알파 값을 다르게 해서 시도\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge 메타 모델 학습\n",
    "meta_model = Ridge(alpha= 5)  \n",
    "meta_model.fit(train_meta_df, y_df)\n",
    "\n",
    "# 최종 예측 수행\n",
    "final_preds = meta_model.predict(test_meta_df)\n",
    "\n",
    "# ----------------------------------------------------------- 제출 파일 -----------------------------------------------------------------\n",
    "\n",
    "# 제출 파일 생성\n",
    "ridge_sub2 = sub.copy()\n",
    "ridge_sub2['Price'] = final_preds\n",
    "ridge_sub2.to_csv('ridge_sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
